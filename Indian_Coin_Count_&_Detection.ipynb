{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "V3TB8fl8Giww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41d78776-c774-4b2c-8326-537b11dcb55f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ultralytics (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/THU-MIG/yolov10.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !wget -P -q https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10n.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O74tX_o1J5nM",
        "outputId": "eb95cf84-c059-43df-8455-3a24156c45b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-20 06:06:53--  https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10n.pt\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/THU-MIG/yolov10/releases/download/v1.0/yolov10n.pt [following]\n",
            "--2024-11-20 06:06:54--  https://github.com/THU-MIG/yolov10/releases/download/v1.0/yolov10n.pt\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/804788522/de01476f-8157-4901-921f-e0c6cb3848cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241120%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241120T060654Z&X-Amz-Expires=300&X-Amz-Signature=c2f5f8479b622e2f669155155456660764bce07b9f31e49ad92c1800b3524d69&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov10n.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-11-20 06:06:54--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/804788522/de01476f-8157-4901-921f-e0c6cb3848cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241120%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241120T060654Z&X-Amz-Expires=300&X-Amz-Signature=c2f5f8479b622e2f669155155456660764bce07b9f31e49ad92c1800b3524d69&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov10n.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11447983 (11M) [application/octet-stream]\n",
            "Saving to: â€˜-q/yolov10n.ptâ€™\n",
            "\n",
            "yolov10n.pt         100%[===================>]  10.92M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2024-11-20 06:06:54 (160 MB/s) - â€˜-q/yolov10n.ptâ€™ saved [11447983/11447983]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q roboflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uov7HgZOLkbH",
        "outputId": "b9186933-58bf-4e93-93e2-a1fca6edf7d0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/80.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/66.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow"
      ],
      "metadata": {
        "id": "UipHaiUNMAvs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(\"bLFtZJ2hdOOhFjm4ngS4\")\n",
        "project = rf.workspace(\"jaiadityan\").project(\"indian-coin-hqbrx\")\n",
        "version=project.version(1)\n",
        "dataset=version.download(\"yolov8\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ll5nHcbM-zY",
        "outputId": "7b0da943-6f1b-4061-e07c-e4070e3f12a4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in indian-coin-1 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111796/111796 [00:02<00:00, 38137.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to indian-coin-1 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3604/3604 [00:00<00:00, 5011.99it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=train epochs=25 batch=32 plots=True \\\n",
        "model=\"/content/-q/yolov10n.pt\" data=\"/content/indian-coin-1/data.yaml\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f57C--itQYA3",
        "outputId": "5aabdd87-b759-4e83-8077-a74462d5ae0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(file, map_location=\"cpu\")\n",
            "New https://pypi.org/project/ultralytics/8.3.34 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.1.34 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/-q/yolov10n.pt, data=/content/indian-coin-1/data.yaml, epochs=25, time=None, patience=100, batch=32, imgsz=640, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/yolov10/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 25.0MB/s]\n",
            "2024-11-20 07:14:04.199652: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-20 07:14:04.219048: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-20 07:14:04.224920: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n",
            " 23        [16, 19, 22]  1    862888  ultralytics.nn.modules.head.v10Detect        [4, [64, 128, 256]]           \n",
            "YOLOv10n summary: 385 layers, 2708600 parameters, 2708584 gradients, 8.4 GFLOPs\n",
            "\n",
            "Transferred 493/595 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLOv10\n",
        "model = YOLOv10(\" \")\n",
        "model(source=\"\",conf = 0.25, save=True)"
      ],
      "metadata": {
        "id": "6GcKMG7wZd9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "images = glob.glob(\"\")\n",
        "images_to_display = images[:10]\n",
        "\n",
        "fig,axes = plt.subplots(4,5, figsize=(20,10))\n",
        "\n",
        "for i, ax in enumerate(axes.flat)\n",
        "  if i<len(images_to_diaplay)\n",
        "    img = mpimg.imread(images_to_diaplay[i])\n",
        "    ax.inshow(img)\n",
        "    ax.axis(\"off\")\n",
        "    else:\n",
        "      ax.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "BJ_UzzmYdnHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " import cv2\n",
        " import matplotlib.pyplot as plt\n",
        " from collections import Counter\n",
        "\n",
        "\n",
        " image_path = \"\"\n",
        "\n",
        " result= model.predict(source = image_path, imgsz = 640, conf = 0.15)\n",
        " annotated_img = result[0].plot()\n",
        " annotated_img[:,:,::-1]\n",
        " plt.imshow(annotated_img[:,:,::-1])\n",
        "\n",
        "\n",
        "  detections = result[0].boxex.data\n",
        "\n",
        "  class_names = [model.names[int(cls)] for cls in detections[:,5]]\n",
        "  class_names\n",
        "  count = Counter(class_name)\n",
        "  rupees_values = {\n",
        "      \"1\" :1,\n",
        "      \"2\" :2,\n",
        "      \"5\" :5,\n",
        "      \"10\" :10,\n",
        "  }\n",
        "  total_values= sum(rupees_values[name] for name, count in count.items())\n",
        "  detection_str = \", \".join([f\"{name}: {count}\" for name, count in count.items()])\n",
        "  print(detection_str)\n",
        "  print(total_values)\n"
      ],
      "metadata": {
        "id": "0MAX25lZfgaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(annotated_img[:,:,::-1])"
      ],
      "metadata": {
        "id": "AWHT-tdUh5Zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detections = result[0].boxex.data\n",
        "detections\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qUE_l-CZiXXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = Counter(class_name)"
      ],
      "metadata": {
        "id": "Pp_aafhAjl-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count"
      ],
      "metadata": {
        "id": "jWr0XOQIkCKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " total_values"
      ],
      "metadata": {
        "id": "ZeKLBlAqkVOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n"
      ],
      "metadata": {
        "id": "h9rSxfYtlox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import cv2\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def predict(image):\n",
        "  cv2.cvColor(image, cv2.COLOR_BGR2BGR)\n",
        "  result= model.predict(source = image_path, imgsz = 640, conf = 0.15)\n",
        "  annotated_img = result[0].plot()\n",
        "  annotated_img[:,:,::-1]\n",
        "  plt.imshow(annotated_img[:,:,::-1])\n",
        "\n",
        "\n",
        "    detections = result[0].boxex.data\n",
        "\n",
        "    class_names = [model.names[int(cls)] for cls in detections[:,5]]\n",
        "    class_names\n",
        "    count = Counter(class_name)\n",
        "    rupees_values = {\n",
        "        \"1\" :1,\n",
        "        \"2\" :2,\n",
        "        \"5\" :5,\n",
        "        \"10\" :10,\n",
        "    }\n",
        "    total_values= sum(rupees_values[name] for name, count in count.items())\n",
        "    detection_str = \", \".join([f\"{name}: {count}\" for name, count in count.items()])\n",
        "    print(detection_str)\n",
        "    print(total_values)\n",
        "    annotated_images = annotated_img[:,:,::-1]\n",
        "    return annotated_img, detection_str, total_values\n",
        "\n",
        "\n",
        "   app = gr.interface(predict,\n",
        "               inputs = gr.Image(type = \"numpy\", label = \"upload an image here\"))\n",
        "               outputs = [gr.Image(type=\"numpy\", label = \"annotated_images\"), gr.Textbox(\"Detection Count\"), gr.Textbox(\"Total Rupees\")]\n",
        "               totle = \"Indian Coin Count & Detection\"\n",
        "               Description = \"upload an image and the yolov10 model will detect and countt the images \"\n",
        "   app.launch()"
      ],
      "metadata": {
        "id": "zqyDwKzzmd3n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}